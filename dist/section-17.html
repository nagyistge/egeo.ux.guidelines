<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <title>Egeo documentation</title>
    <meta name="description" content="" />
    <meta name="generator" content="kss-node" />
    <link href='http://guide.stratio.com/public/favicon.ico' rel='icon' type='image/x-icon'>
    <link rel="stylesheet" href="public/kss.css" />
    <link rel="stylesheet" href="public/styleguide.css">

    <!--[if lt IE 9]>
    <script src="public/html5shiv.js"></script>
    <![endif]-->
  </head>
  <body id="kss-node" data-ng-app="myApp">
    <div class="kss-wrapper">
      <div class="kss-sidebar">
        <div class="kss-sidebar-inner">
          <header class="kss-header">
            <div class="logo"><a href="/web/"><img src='public/assets/images/header.logo.png' /></a></div>
            <h1 class="kss-doc-title"><a href="./">Egeo documentation</a></h1>
            <div class="version">v0.1.0</div>
          </header>
          <nav class="kss-nav">
            <ul class="kss-menu" data-kss-ref="17">
              <li class="kss-menu-item"><a href="./"><span class="kss-ref">0</span><span class="kss-name">Overview</span></a></li>
              <li class="kss-menu-item"><a href="section-1.html"><span class="kss-ref">1</span><span class="kss-name">Design Process and Evaluation</span></a></li>
              <li class="kss-menu-item"><a href="section-2.html"><span class="kss-ref">2</span><span class="kss-name">Optimizing the User Experience</span></a></li>
              <li class="kss-menu-item"><a href="section-3.html"><span class="kss-ref">3</span><span class="kss-name">Accessibility</span></a></li>
              <li class="kss-menu-item"><a href="section-4.html"><span class="kss-ref">4</span><span class="kss-name">Hardware and Software</span></a></li>
              <li class="kss-menu-item"><a href="section-5.html"><span class="kss-ref">5</span><span class="kss-name">The Home Page</span></a></li>
              <li class="kss-menu-item"><a href="section-6.html"><span class="kss-ref">6</span><span class="kss-name">Page Layout</span></a></li>
              <li class="kss-menu-item"><a href="section-7.html"><span class="kss-ref">7</span><span class="kss-name">Navigation</span></a></li>
              <li class="kss-menu-item"><a href="section-8.html"><span class="kss-ref">8</span><span class="kss-name">Scrolling and Paging</span></a></li>
              <li class="kss-menu-item"><a href="section-9.html"><span class="kss-ref">9</span><span class="kss-name">Headings, Titles, and Labels</span></a></li>
              <li class="kss-menu-item"><a href="section-10.html"><span class="kss-ref">10</span><span class="kss-name">Links</span></a></li>
              <li class="kss-menu-item"><a href="section-11.html"><span class="kss-ref">11</span><span class="kss-name">Text Appearance</span></a></li>
              <li class="kss-menu-item"><a href="section-12.html"><span class="kss-ref">12</span><span class="kss-name">Lists</span></a></li>
              <li class="kss-menu-item"><a href="section-13.html"><span class="kss-ref">13</span><span class="kss-name">Graphics and Media</span></a></li>
              <li class="kss-menu-item"><a href="section-14.html"><span class="kss-ref">14</span><span class="kss-name">Content Organization</span></a></li>
              <li class="kss-menu-item"><a href="section-15.html"><span class="kss-ref">15</span><span class="kss-name">Search</span></a></li>
              <li class="kss-menu-item"><a href="section-16.html"><span class="kss-ref">16</span><span class="kss-name">Screen - Based controls (Widgets)</span></a></li>
              <li class="kss-menu-item"><a href="section-17.html"><span class="kss-ref">17</span><span class="kss-name">Usability testing</span></a></li>
            </ul>
            <ul class="kss-menu-child">
              <li class="kss-menu-item"><a href="#section-17.1"><span class="kss-ref">17.1</span><span class="kss-name">Use an iterative design approach (4:5)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.2"><span class="kss-ref">17.2</span><span class="kss-name">Solicit comments from test participants (3:4)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.3"><span class="kss-ref">17.3</span><span class="kss-name">Evaluate a site before and after making changes (3:3)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.4"><span class="kss-ref">17.4</span><span class="kss-name">Prioritize tasks (3:2)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.5"><span class="kss-ref">17.5</span><span class="kss-name">Consider frequency and severity (3:3)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.6"><span class="kss-ref">17.6</span><span class="kss-name">Select the right number of test participants (3:4)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.7"><span class="kss-ref">17.7</span><span class="kss-name">Use the appropriate prototyping technology (2:3)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.8"><span class="kss-ref">17.8</span><span class="kss-name">Use inspection evaluation results cautiously (2:4)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.9"><span class="kss-ref">17.9</span><span class="kss-name">Recognize the &quot;evaluator effect&quot; (2:4)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.10"><span class="kss-ref">17.10</span><span class="kss-name">Apply automatic evaluation methods (1:3)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.11"><span class="kss-ref">17.11</span><span class="kss-name">Use cognitive walkthroughs cautiously (1:4)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.12"><span class="kss-ref">17.12</span><span class="kss-name">Choosing a testing venue (1:4)</span></a></li>
              <li class="kss-menu-item"><a href="#section-17.13"><span class="kss-ref">17.13</span><span class="kss-name">Use severity ratings cautiously (1:4)</span></a></li>
            </ul>
          </nav>
        </div>
      </div>
      <div class="kss-content">
        <article class="kss-article">
          <section id="section-17" class="kss-section kss-depth-1">
            <h1 class="kss-title"><span class="kss-ref">17</span> Usability testing</h1>
            <div class="kss-description">
              <p>There are two major considerations when conducting usability testing. The first is to ensure that the best possible method for testing is used. Generally, the best method is to conduct a test where representative participants interact with representative scenarios. The tester collects data on the participant’s success, speed of performance, and satisfaction. The findings, including both quantitative data and qualitative observations information, are provided to designers in a test report. Using ’inspection evaluations,’ in place of well-controlled usability tests, must be done with caution. Inspection methods, such as heuristic evaluations or expert reviews, tend to generate large numbers of potential usability ’problems’ that never turn out to be actual usability problems.</p>
<p>The second major consideration is to ensure that an iterative approach is used. After the first test results are provided to designers, they should make changes and then have the Web site tested again. Generally, the more iterations, the better the Web site.</p>

            </div>
          </section>
          <section id="section-17.1" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.1</span> Use an iterative design approach (4:5)</h1>
            <div class="kss-description">
              <p><strong>Develop and test prototypes through an iterative design approach to create the most useful and usable Web site.</strong></p>
<p> Iterative design consists of creating paper or computer prototypes, testing the prototypes, and then making changes based on the test results. The ’test and make changes’ process is repeated until the website meets performance benchmarks (usability goals). When these goals are met, the iterative process ends. The iterative design process helps to substantially improve the usability of websites, improve task completion rates, and improve user satisfaction.</p>

            </div>
          </section>
          <section id="section-17.2" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.2</span> Solicit comments from test participants (3:4)</h1>
            <div class="kss-description">
              <p><strong> Solicit usability testing participants&#39; comments either during or after the performance of tasks.</strong></p>
<p>Solicit comments from test participants by asking participants to think aloud when performing tasks, or report opinions after completed tasks (retrospectively). The ‘think aloud’ method allows participants to report incidents as they happen, but may result in fewer completed tasks, and fewer negative reports. The retrospective method allows participants to report ‘critical incidents’ after viewing their session on video. Both methods can result in positive biased reviews.</p>

            </div>
          </section>
          <section id="section-17.3" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.3</span> Evaluate a site before and after making changes (3:3)</h1>
            <div class="kss-description">
              <p><strong>Conduct &#39;before and after&#39; studies when revising a Web site to determine changes in usability.</strong></p>
<p>Conducting usability studies prior to and after a redesign will help designers determine if changes actually made a difference in the usability of the site. One study reported that only twenty-two percent of users were able to buy items on an original Web site. After a major redesign effort, eighty-eight percent of users successfully purchased products on that site.</p>

            </div>
          </section>
          <section id="section-17.4" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.4</span> Prioritize tasks (3:2)</h1>
            <div class="kss-description">
              <p><strong>Give high priority to usability issues preventing &#39;easy&#39; tasks from being easy.</strong></p>
<p>When deciding which usability issues to fix first, address the tasks that users believe to be easy but are actually difficult. The Usability Magnitude Estimation (UME) is a measure that can be used to assess user expectations of the difficulty of each task. Participants judge how difficult or easy a task will be before trying to do it, and then make a second judgment after trying to complete the task. Each task is eventually put into one of four categories based on these expected versus actual ratings:</p>
<ul>
<li><p>Tasks that were expected to be easy, but were actually difficult;</p>
</li>
<li><p>Tasks that were expected to be difficult, but were actually easy;</p>
</li>
<li><p>Tasks that were expected to be easy and were actually easy; and</p>
</li>
<li><p>Tasks that were expected to be difficult and were difficult to complete.</p>
</li>
</ul>

            </div>
          </section>
          <section id="section-17.5" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.5</span> Consider frequency and severity (3:3)</h1>
            <div class="kss-description">
              <p><strong> Distinguish between frequency and severity when reporting on usability issues and problems.</strong></p>
<p>The number of users affected determines the frequency of a problem. To be most useful, the severity of a problem should be defined by analyzing difficulties encountered by individual users. Both frequency and severity data can be used to prioritize usability issues that need to be changed. For example, designers should focus first on fixing those usability issues that were shown to be most severe. Those usability issues that were encountered by many participants, but had a severity rating of &#39;nuisance&#39;, should be given much less priority.</p>

            </div>
          </section>
          <section id="section-17.6" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.6</span> Select the right number of test participants (3:4)</h1>
            <div class="kss-description">
              <p><strong>Select the right number of participants when using different usability techniques. Using too few may reduce the usability of a Web site; using too many wastes valuable resources.</strong></p>
<p>Selecting the number of participants to use when conducting usability evaluations depends on the method being used:</p>
<p>Inspection evaluation by usability specialists:</p>
<ul>
<li><p>The typical goal of an inspection evaluation is to have usability experts separately inspect a user interface by applying a set of broad usability guidelines. This is usually done with two to five people.</p>
</li>
<li><p>The research shows that as more experts are involved in evaluating the usability of the product, the greater the number of usability issues will be identified. However, for every true usability problem identified, there will be at least one usability issue that is not a real problem. Having more evaluators does decrease the number of misses, but is also increases the number of false positives. Generally, the more expert the usability specialists, the more useful the results.</p>
</li>
</ul>
<p>Performance usability testing with users:</p>
<ul>
<li><p>Early in the design process, usability testing with a small number of users (approximately six) is sufficient to identify problems with the information architecture (navigation) and overall design issues. If the Web site has very different types of users (e.g., novices and experts), it is important to test with six or more of each type of user. Another critical factor in this preliminary testing is having trained usability specialists as the usability test facilitator and primary observers.</p>
</li>
<li><p>Once the navigation, basic content, and display features are in place, quantitative performance testing (measuring times, wrong pathways, failure to find content, etc.) can be conducted to ensure that usability objectives are being met. To measure each usability objective to a particular confidence level, such as ninety-five percent, requires a larger number of users in the usability tests.</p>
</li>
<li><p>When the performance of two sites is compared (i.e., an original site and a revised site), quantitative usability testing should be employed. Depending on how confident the usability specialist wants to be in the tests could require a larger number of participants.</p>
</li>
<li><p>It is best to perform iterative cycles of usability testing over the course of the Web site’s development. This enables usability specialists and designers to observe and listen to many users.</p>
</li>
</ul>

            </div>
          </section>
          <section id="section-17.7" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.7</span> Use the appropriate prototyping technology (2:3)</h1>
            <div class="kss-description">
              <p><strong>Create prototypes using the most appropriate technology for the phase of the design, the required fidelity of the prototype, and skill of the person creating the prototype.</strong></p>
<p>Designers can use either paper-based or computer-based prototypes. Paper-based prototyping appears to be as effective as computer-based prototyping when trying to identify most usability issues. Several studies have shown that there was no reliable difference in the number of usability issues detected between computer and paper prototypes. However, usability test participants usually prefer interacting with computer-based prototypes. Paper prototypes can be used when it is necessary to view and evaluate many different (usually early) design ideas, or when computer-based prototyping does not support the ideas the designer wants to implement, or when all members of the design team need to be included–even those that do not know how to create computer-based prototypes.</p>
<p>Software tools that are available to assist in the rapid development of prototypes include PowerPoint, Visio, including other HTML base tools. PowerPoint can be used to create medium fidelity prototypes. These prototypes can be both interactive and dynamic, and are useful when the design requires more than a ’pencil-and-paper’ prototype.</p>

            </div>
          </section>
          <section id="section-17.8" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.8</span> Use inspection evaluation results cautiously (2:4)</h1>
            <div class="kss-description">
              <p><strong>Use inspection evaluation results with caution.</strong></p>
<p>Inspection evaluations include heuristic evaluations, expert reviews, and cognitive walkthroughs. It is a common practice to conduct an inspection evaluation to try to detect and resolve obvious problems before conducting usability tests. Inspection evaluations should be used cautiously because several studies have shown that they appear to detect far more potential problems than actually exist, and they also tend to miss some real problems. On average, for every hit there will be about 1.3 false positives and .5 misses.</p>
<p>Another recent study concluded that the low effectiveness of heuristic evaluations as a whole was worrisome because of the low problem detection rate (p=.09), and the large number of evaluators required (16) to uncover seventy-five percent of the potential usability issues.</p>
<p>Another difficulty when conducting heuristic evaluations is that evaluators frequently apply the wrong heuristic, which can mislead designers that are trying to fix the problem. One study reported that only thirty-nine percent of the heuristics were appropriately applied.</p>
<p>Evaluators seem to have the most success identifying usability issues that can be seen by merely looking at the display, and the least success finding issues that require users to take several steps (clicks) to a target.</p>
<p>Heuristic evaluations and expert reviews may best be used to identify potential usability issues to evaluate during usability testing. To improve somewhat on the performance of heuristic evaluations, evaluators can use the ’usability problem inspector’ (UPI) method or the ’Discovery and Analysis Resource’ (DARe) method.</p>

            </div>
          </section>
          <section id="section-17.9" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.9</span> Recognize the &quot;evaluator effect&quot; (2:4)</h1>
            <div class="kss-description">
              <p><strong>Beware of the &#39;evaluator&#39; effect when conducting inspection evaluations.</strong></p>
<p>The ’evaluator effect’ occurs when multiple evaluators evaluating the same interface detect markedly different sets of problems. The evaluators may be doing an expert review, heuristic evaluation, or cognitive walkthrough. The evaluator effect exists for evaluators who are novice or experienced, while detecting cosmetic and severe problems, and when evaluating simple or complex websites. In fact, when using multiple evaluators, any one evaluator is unlikely to detect the majority of the ’severe’ problems that will be detected collectively by all evaluators. Evaluators also tend to perceive the problems they detected as more severe than the problems detected by others.</p>

            </div>
          </section>
          <section id="section-17.10" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.10</span> Apply automatic evaluation methods (1:3)</h1>
            <div class="kss-description">
              <p><strong>Use appropriate automatic evaluation methods to conduct initial evaluations on Web sites.</strong></p>
<p>An automatic evaluation method is one where software is used to evaluate a Web site. An automatic evaluation tool can help find certain types of design difficulties, such as pages that will load slowly, missing links, use of jargon, potential accessibility problems, etc. While automatic evaluation methods are useful, they should not be used as a substitute for evaluations or usability testing with typical users. There are many commercially available automatic evaluation methods available for checking on a variety of Web site parameters.</p>

            </div>
          </section>
          <section id="section-17.11" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.11</span> Use cognitive walkthroughs cautiously (1:4)</h1>
            <div class="kss-description">
              <p><strong>Use cognitive walkthroughs with caution.</strong></p>
<p>Cognitive walkthroughs are often conducted to resolve obvious problems before conducting performance tests. The cognitive walkthrough appears to detect far more potential problems than actually exist, when compared with performance usability testing results.</p>

            </div>
          </section>
          <section id="section-17.12" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.12</span> Choosing a testing venue (1:4)</h1>
            <div class="kss-description">
              <p><strong>Testers can use either laboratory or remote usability testing because they both elicit similar results.</strong></p>
<p>In laboratory-based testing, the participant and the tester are in the same physical location. In remote testing, the tester and the participant are in different physical locations. Remote testing provides the opportunity for participants to take a test in their home or office. It is convenient for participants because it requires no travel to a test facility.</p>

            </div>
          </section>
          <section id="section-17.13" class="kss-section kss-depth-2">
            <h1 class="kss-title"><span class="kss-ref">17.13</span> Use severity ratings cautiously (1:4)</h1>
            <div class="kss-description">
              <p><strong>Use severity ratings with caution.</strong></p>
<p>Most designers would like usability specialists to prioritize design problems that they found either by inspection evaluations or expert reviews. So that they can decide which issues to fix first, designers would like the list of potential usability problems ranked by each ones severity level. The research literature is fairly clear that even highly experienced usability specialists cannot agree on which usability issues will have the greatest impact on usability.</p>
<p>One study had 17 expert review and usability test teams evaluate and test the same Web page. The teams had one week to do an expert review, or two weeks to do a usability test. Each team classified each usability issue as a minor problem, serious problem, or critical problem. There was considerable disagreement in which problems the teams judged as minor, serious or critical, and there was little agreement on which were the top five problems. Another study reported that heuristic evaluators overestimated severity twenty-two percent of the time, and underestimated severity seventy-eight percent of the time when compared with usability testing results.</p>

            </div>
          </section>
        </article>
        <footer class="kss-footer">
          <div>Created using <a href="https://github.com/hughsk/kss-node">kss-node</a> and <a href="https://github.com/htanjo/kss-node-template">kss-node-template</a>.</div>
        </footer>
      </div>
    </div>
    <script src="public/kss.js"></script>
    <script src="public/jquery-1.9.1.min.js"></script>
    <!--[if gt IE 8]><!-->
    <script src="public/rainbow.min.js"></script>
    <!--<![endif]-->
    <script src="public/main.js"></script>
    
  </body>
</html>
